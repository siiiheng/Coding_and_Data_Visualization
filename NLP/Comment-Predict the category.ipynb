{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import html\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.corpus import wordnet\n",
    "from typing import List\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import spacy\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import SimpleRNN, LSTM\n",
    "from keras.layers import Flatten, Masking\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>itunes_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>itunes_url</th>\n",
       "      <th>podcast_title</th>\n",
       "      <th>category</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b313ef8ef0d5b64290d3036ff1bbf2d2</td>\n",
       "      <td>감성 라디오 음악도시</td>\n",
       "      <td>미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...</td>\n",
       "      <td>5</td>\n",
       "      <td>664CCA7142E9AE8</td>\n",
       "      <td>2011-09-14T13:25:46-07:00</td>\n",
       "      <td>442838670</td>\n",
       "      <td>fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/fm-%EC%9...</td>\n",
       "      <td>FM 음악도시(종영)</td>\n",
       "      <td>music</td>\n",
       "      <td>감성 라디오 음악도시 미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀...</td>\n",
       "      <td>감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abfb842993be20d21bfae7103addc5e9</td>\n",
       "      <td>They’ve really cut back on the content this se...</td>\n",
       "      <td>Last season there was a new pod every 3-4 days...</td>\n",
       "      <td>1</td>\n",
       "      <td>AD790CE113DCBC1</td>\n",
       "      <td>2018-04-11T13:46:47-07:00</td>\n",
       "      <td>1015394113</td>\n",
       "      <td>the-good-phight-for-philadelphia-phillies-fans</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/the-good...</td>\n",
       "      <td>The Good Phight: for Philadelphia Phillies fans</td>\n",
       "      <td>sports</td>\n",
       "      <td>They’ve really cut back on the content this se...</td>\n",
       "      <td>they ’ ve really cut back on the content this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         podcast_id  \\\n",
       "0  b313ef8ef0d5b64290d3036ff1bbf2d2   \n",
       "1  abfb842993be20d21bfae7103addc5e9   \n",
       "\n",
       "                                               title  \\\n",
       "0                                        감성 라디오 음악도시   \n",
       "1  They’ve really cut back on the content this se...   \n",
       "\n",
       "                                             content  rating        author_id  \\\n",
       "0  미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...       5  664CCA7142E9AE8   \n",
       "1  Last season there was a new pod every 3-4 days...       1  AD790CE113DCBC1   \n",
       "\n",
       "                  created_at   itunes_id  \\\n",
       "0  2011-09-14T13:25:46-07:00   442838670   \n",
       "1  2018-04-11T13:46:47-07:00  1015394113   \n",
       "\n",
       "                                                slug  \\\n",
       "0  fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...   \n",
       "1     the-good-phight-for-philadelphia-phillies-fans   \n",
       "\n",
       "                                          itunes_url  \\\n",
       "0  https://podcasts.apple.com/us/podcast/fm-%EC%9...   \n",
       "1  https://podcasts.apple.com/us/podcast/the-good...   \n",
       "\n",
       "                                     podcast_title category  \\\n",
       "0                                      FM 음악도시(종영)    music   \n",
       "1  The Good Phight: for Philadelphia Phillies fans   sports   \n",
       "\n",
       "                                             reviews  \\\n",
       "0  감성 라디오 음악도시 미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀...   \n",
       "1  They’ve really cut back on the content this se...   \n",
       "\n",
       "                                         reviews_new  \n",
       "0  감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...  \n",
       "1  they ’ ve really cut back on the content this ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "\n",
    "df = pd.read_csv('df_lem.csv', lineterminator='\\n', index_col = 0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comedy        0.16038\n",
       "society       0.12890\n",
       "news          0.10412\n",
       "business      0.07566\n",
       "sports        0.07178\n",
       "arts          0.06362\n",
       "education     0.05976\n",
       "crime         0.05042\n",
       "health        0.04706\n",
       "tv            0.04354\n",
       "religion      0.04186\n",
       "leisure       0.03452\n",
       "history       0.02834\n",
       "kids          0.02448\n",
       "music         0.01782\n",
       "science       0.01640\n",
       "fiction       0.01552\n",
       "government    0.00826\n",
       "technology    0.00756\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge similar categories into a new or existing category, for minor categories we categorize them as 'others'\n",
    "\n",
    "import re\n",
    "def replace_cat(line):\n",
    "    line = re.sub(r'\\b(society|religion|government|history|education|kids)\\b', 'society', line)\n",
    "    line = re.sub(r'\\b(tv|leisure|sports|music|fiction|arts)\\b', 'entertainment', line)\n",
    "    line = re.sub(r'\\b(science|technology|health|crime)\\b', 'others', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = df['category'].apply(lambda x: replace_cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "society        0.29160\n",
       "entertament    0.24680\n",
       "comedy         0.16038\n",
       "others         0.12144\n",
       "news           0.10412\n",
       "business       0.07566\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat review title and review content to get more information later\n",
    "\n",
    "df['reviews_title'] = df['reviews_new'] + ' ' + df['podcast_title']\n",
    "df['reviews_title'] = df['reviews_title'].astype(str)\n",
    "df['reviews_title'] = df['reviews_title'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex and text preprocessing\n",
    "\n",
    "def word_replace(line):\n",
    "    line = re.sub(r'\\b(pod(s?|casts?)|listen|love|great|episodes?|just|good|make|time|really)\\b', '', line)\n",
    "    line = re.sub(r'\\b(story|talk|people|host|guy|say|don|know|way|work|want|need|best|new|life)\\b', '', line)\n",
    "    line = re.sub(r'\\b(guest|thing|think|feel|look|come|use|year|minutes?|lot|thank|favorite)\\b', '', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_title'] = df['reviews_title'].apply(lambda x: word_replace(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"category\"]\n",
    "docs = df[\"reviews_title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "labels = to_categorical(encoder.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use spacy package to remove the stopwords\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "stopwords_removed_docs = list(\n",
    "    map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(stopwords_removed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))\n",
    "\n",
    "# get the max length in terms of token length\n",
    "max_length = get_max_token_length_per_doc(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "# integer encode the documents\n",
    "encoded_docs = integer_encode_documents(stopwords_removed_docs, tokenizer)\n",
    "# this is a list of lists, the numbers represent the index position of that word.\n",
    "# for instance, 33 means the 33rd word in the vocabulary\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 500)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toolkit\n",
    "\n",
    "VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Here we use GloVe vectors\n",
    "\n",
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('../datasets/glove.6B.100d.txt') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    " # create a weight matrix for words in training docs\n",
    "    \n",
    "embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "def make_classification_rnn_model(plot=False):\n",
    "    model = Sequential() # keras model\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(SimpleRNN(units=64, input_shape=(1, MAX_SEQUENCE_LENGTH)))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(6, activation='softmax')) # we changed the number of categories from 19 to 6\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model\n",
    "\n",
    "def make_lstm_classification_model(plot=False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(LSTM(units=32, input_shape=(1, MAX_SEQUENCE_LENGTH)))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(6, activation='softmax')) # we changed the number of categories from 19 to 6\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 500, 100)          5695400   \n",
      "                                                                 \n",
      " masking_4 (Masking)         (None, 500, 100)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                17024     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,713,054\n",
      "Trainable params: 17,654\n",
      "Non-trainable params: 5,695,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = make_lstm_classification_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 252s 197ms/step - loss: 1.2523 - accuracy: 0.5207\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 253s 202ms/step - loss: 0.9844 - accuracy: 0.6396\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 246s 197ms/step - loss: 0.8564 - accuracy: 0.6957\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 240s 192ms/step - loss: 0.7753 - accuracy: 0.7266\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 236s 189ms/step - loss: 0.7189 - accuracy: 0.7515\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 0.6754 - accuracy: 0.7675\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 260s 208ms/step - loss: 0.6405 - accuracy: 0.7792\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 254s 203ms/step - loss: 0.6117 - accuracy: 0.7886\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 0.5861 - accuracy: 0.7997\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 259s 207ms/step - loss: 0.5647 - accuracy: 0.8083\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 260s 208ms/step - loss: 0.5447 - accuracy: 0.8153\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 253s 202ms/step - loss: 0.5273 - accuracy: 0.8202\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 240s 192ms/step - loss: 0.5109 - accuracy: 0.8267\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 240s 192ms/step - loss: 0.4953 - accuracy: 0.8320\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 233s 186ms/step - loss: 0.4806 - accuracy: 0.8356\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 213s 171ms/step - loss: 0.4684 - accuracy: 0.8393\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 254s 203ms/step - loss: 0.4568 - accuracy: 0.8440\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 234s 187ms/step - loss: 0.4428 - accuracy: 0.8498\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 234s 187ms/step - loss: 0.4322 - accuracy: 0.8522\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 216s 173ms/step - loss: 0.4209 - accuracy: 0.8563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdea1e90710>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "lstm.fit(X_train, y_train, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 25s 67ms/step - loss: 0.8704 - accuracy: 0.7482\n",
      "Accuracy: 74.820000\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "loss, accuracy = lstm.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 27s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_lstm = lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = encoder.inverse_transform(predictions_lstm.argmax(axis=1))\n",
    "true = encoder.inverse_transform(y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2273,  293,  121,   65,   82,  120],\n",
       "       [ 241, 1885,  146,   74,   53,   61],\n",
       "       [ 110,  218, 1143,   30,   25,   25],\n",
       "       [  77,   96,   30,  835,   20,   14],\n",
       "       [  84,   98,   23,   18,  474,   33],\n",
       "       [ 150,  103,   38,   25,   45,  872]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['society', 'entertainment', 'comedy', 'news', 'business', 'others']\n",
    "confusion_matrix = confusion_matrix(true, pred, labels=labels)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>society</th>\n",
       "      <th>entertament</th>\n",
       "      <th>comedy</th>\n",
       "      <th>news</th>\n",
       "      <th>business</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>society</th>\n",
       "      <td>2273</td>\n",
       "      <td>293</td>\n",
       "      <td>121</td>\n",
       "      <td>65</td>\n",
       "      <td>82</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertament</th>\n",
       "      <td>241</td>\n",
       "      <td>1885</td>\n",
       "      <td>146</td>\n",
       "      <td>74</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>110</td>\n",
       "      <td>218</td>\n",
       "      <td>1143</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>77</td>\n",
       "      <td>96</td>\n",
       "      <td>30</td>\n",
       "      <td>835</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>84</td>\n",
       "      <td>98</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>474</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>150</td>\n",
       "      <td>103</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             society  entertament  comedy  news  business  others\n",
       "society         2273          293     121    65        82     120\n",
       "entertament      241         1885     146    74        53      61\n",
       "comedy           110          218    1143    30        25      25\n",
       "news              77           96      30   835        20      14\n",
       "business          84           98      23    18       474      33\n",
       "others           150          103      38    25        45     872"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix, \n",
    "    index=['society', 'entertainment', 'comedy', 'news', 'business', 'others'], \n",
    "    columns=['society', 'entertainment', 'comedy', 'news', 'business', 'others']\n",
    ")\n",
    "cmtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9348939055838481"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate roc-auc score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, predictions_lstm, multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 500, 100)          5695400   \n",
      "                                                                 \n",
      " masking_5 (Masking)         (None, 500, 100)          0         \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 64)                10560     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,707,102\n",
      "Trainable params: 11,702\n",
      "Non-trainable params: 5,695,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Here we try RNN model\n",
    "\n",
    "rnn = make_classification_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 183s 145ms/step - loss: 1.3133 - accuracy: 0.5009\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 173s 139ms/step - loss: 1.1269 - accuracy: 0.5842\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 184s 147ms/step - loss: 1.0415 - accuracy: 0.6230\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 164s 131ms/step - loss: 0.9721 - accuracy: 0.6520\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 169s 135ms/step - loss: 0.9182 - accuracy: 0.6753\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 155s 124ms/step - loss: 0.8770 - accuracy: 0.6916\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 163s 131ms/step - loss: 0.8407 - accuracy: 0.7061\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 183s 146ms/step - loss: 0.8108 - accuracy: 0.7164\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 156s 125ms/step - loss: 0.7876 - accuracy: 0.7269\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 176s 141ms/step - loss: 0.7664 - accuracy: 0.7351\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 163s 130ms/step - loss: 0.7472 - accuracy: 0.7417\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 174s 139ms/step - loss: 0.7339 - accuracy: 0.7461\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 178s 143ms/step - loss: 0.7176 - accuracy: 0.7529\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 160s 128ms/step - loss: 0.7030 - accuracy: 0.7571\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 184s 147ms/step - loss: 0.6894 - accuracy: 0.7627\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 178s 143ms/step - loss: 0.6801 - accuracy: 0.7655\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 167s 134ms/step - loss: 0.6690 - accuracy: 0.7707\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 160s 128ms/step - loss: 0.6595 - accuracy: 0.7727\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 177s 142ms/step - loss: 0.6510 - accuracy: 0.7768\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 159s 127ms/step - loss: 0.6414 - accuracy: 0.7810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde8126dc90>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "rnn.fit(X_train, y_train, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 17s 51ms/step - loss: 0.9428 - accuracy: 0.6943\n",
      "Accuracy: 69.430000\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = rnn.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 19s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_rnn = rnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087750481287475"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate roc-auc score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, predictions_rnn, multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rnn = encoder.inverse_transform(predictions_lstm.argmax(axis=1))\n",
    "true_rnn = encoder.inverse_transform(y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2273,  293,  121,   65,   82,  120],\n",
       "       [ 241, 1885,  146,   74,   53,   61],\n",
       "       [ 110,  218, 1143,   30,   25,   25],\n",
       "       [  77,   96,   30,  835,   20,   14],\n",
       "       [  84,   98,   23,   18,  474,   33],\n",
       "       [ 150,  103,   38,   25,   45,  872]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['society', 'entertainment', 'comedy', 'news', 'business', 'others']\n",
    "confusion_matrix_rnn = confusion_matrix(true_rnn, pred_rnn, labels=labels)\n",
    "confusion_matrix_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>society</th>\n",
       "      <th>entertament</th>\n",
       "      <th>comedy</th>\n",
       "      <th>news</th>\n",
       "      <th>business</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>society</th>\n",
       "      <td>2273</td>\n",
       "      <td>293</td>\n",
       "      <td>121</td>\n",
       "      <td>65</td>\n",
       "      <td>82</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertament</th>\n",
       "      <td>241</td>\n",
       "      <td>1885</td>\n",
       "      <td>146</td>\n",
       "      <td>74</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>110</td>\n",
       "      <td>218</td>\n",
       "      <td>1143</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>77</td>\n",
       "      <td>96</td>\n",
       "      <td>30</td>\n",
       "      <td>835</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>84</td>\n",
       "      <td>98</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>474</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>150</td>\n",
       "      <td>103</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             society  entertament  comedy  news  business  others\n",
       "society         2273          293     121    65        82     120\n",
       "entertament      241         1885     146    74        53      61\n",
       "comedy           110          218    1143    30        25      25\n",
       "news              77           96      30   835        20      14\n",
       "business          84           98      23    18       474      33\n",
       "others           150          103      38    25        45     872"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix_rnn, \n",
    "    index=['society', 'entertainment', 'comedy', 'news', 'business', 'others'], \n",
    "    columns=['society', 'entertainment', 'comedy', 'news', 'business', 'others']\n",
    ")\n",
    "cmtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
