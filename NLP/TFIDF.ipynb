{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1fa56ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/en-\n",
      "[nltk_data]     ning.chiang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/en-\n",
      "[nltk_data]     ning.chiang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/en-\n",
      "[nltk_data]     ning.chiang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/en-\n",
      "[nltk_data]     ning.chiang/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pprint import pprint# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel# spaCy for preprocessing\n",
    "import spacy# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7d729e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>itunes_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>itunes_url</th>\n",
       "      <th>podcast_title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b313ef8ef0d5b64290d3036ff1bbf2d2</td>\n",
       "      <td>Í∞êÏÑ± ÎùºÎîîÏò§ ÏùåÏïÖÎèÑÏãú</td>\n",
       "      <td>ÎØ∏Íµ≠ ÏÑúÎ∂ÄÏóê ÏûàÎäî Ïú†ÌïôÏÉùÏù¥ÏóêÏöî. ÏÑ±ÏãúÍ≤ΩÏî® Ï†úÎåÄ ÌõÑ ÎùºÎîîÏò§ Î≥µÍ∑ÄÎßå Í∏∞Îã§Î†§Ïò§Îã§Í∞Ä 6 Ïõî...</td>\n",
       "      <td>5</td>\n",
       "      <td>664CCA7142E9AE8</td>\n",
       "      <td>2011-09-14T13:25:46-07:00</td>\n",
       "      <td>442838670</td>\n",
       "      <td>fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/fm-%EC%9...</td>\n",
       "      <td>FM ÏùåÏïÖÎèÑÏãú(Ï¢ÖÏòÅ)</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abfb842993be20d21bfae7103addc5e9</td>\n",
       "      <td>They‚Äôve really cut back on the content this se...</td>\n",
       "      <td>Last season there was a new pod every 3-4 days...</td>\n",
       "      <td>1</td>\n",
       "      <td>AD790CE113DCBC1</td>\n",
       "      <td>2018-04-11T13:46:47-07:00</td>\n",
       "      <td>1015394113</td>\n",
       "      <td>the-good-phight-for-philadelphia-phillies-fans</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/the-good...</td>\n",
       "      <td>The Good Phight: for Philadelphia Phillies fans</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ebdf879a424547d01862a9bbba18a0f3</td>\n",
       "      <td>Good info. source...</td>\n",
       "      <td>Bob brings a lot of knowledge to any firearm d...</td>\n",
       "      <td>4</td>\n",
       "      <td>E223A4B2642C970</td>\n",
       "      <td>2010-01-19T08:11:43-07:00</td>\n",
       "      <td>333180229</td>\n",
       "      <td>handgun-world-podcast</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/handgun-...</td>\n",
       "      <td>Handgun World Podcast</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab2fdb7db023b223d870487165d11ff3</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>They have lost much of thier credibility by de...</td>\n",
       "      <td>3</td>\n",
       "      <td>E1E7DBE750D119E</td>\n",
       "      <td>2021-01-28T12:21:49-07:00</td>\n",
       "      <td>971901464</td>\n",
       "      <td>wsj-opinion-potomac-watch</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/wsj-opin...</td>\n",
       "      <td>WSJ Opinion: Potomac Watch</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca601bd1524322d0527b16adf2738ff3</td>\n",
       "      <td>Try it now!</td>\n",
       "      <td>Even better than I expected. I was interested ...</td>\n",
       "      <td>5</td>\n",
       "      <td>D7CA4858AFA2CFC</td>\n",
       "      <td>2017-08-24T10:55:20-07:00</td>\n",
       "      <td>1257821731</td>\n",
       "      <td>conversations-with-people-who-hate-me</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/conversa...</td>\n",
       "      <td>Conversations with People Who Hate Me</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>a0f4bdf8c437e34e5b6a17698fbdf64d</td>\n",
       "      <td>üî•Sussyüî•</td>\n",
       "      <td>A little bit $u$, make an episode on plant pol...</td>\n",
       "      <td>2</td>\n",
       "      <td>45C72657925F18D</td>\n",
       "      <td>2022-03-28T07:16:21-07:00</td>\n",
       "      <td>1103320303</td>\n",
       "      <td>but-why-a-podcast-for-curious-kids</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/but-why-...</td>\n",
       "      <td>But Why: A Podcast for Curious Kids</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>d5683ccc88341197ca42aad82111c96f</td>\n",
       "      <td>Jumping butterballs!!</td>\n",
       "      <td>If you are a Marx Brothers fan, and have been ...</td>\n",
       "      <td>5</td>\n",
       "      <td>AAF30F4EAE42219</td>\n",
       "      <td>2018-05-28T18:10:19-07:00</td>\n",
       "      <td>1363963113</td>\n",
       "      <td>the-marx-brothers-council-podcast</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/the-marx...</td>\n",
       "      <td>The Marx Brothers Council Podcast</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>cc546886c2be6370d76bd638f5256ba6</td>\n",
       "      <td>Way too much junkie commercials</td>\n",
       "      <td>I love the show very interesting I‚Äôm telling t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2032AE3B4B98F1F</td>\n",
       "      <td>2020-05-20T17:01:07-07:00</td>\n",
       "      <td>1484888427</td>\n",
       "      <td>autopsy-the-last-hours-of</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/autopsy-...</td>\n",
       "      <td>Autopsy: The Last Hours Of‚Ä¶</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>aaeb50f39da1a9a1d2e3837cf4edb2d0</td>\n",
       "      <td>Awful</td>\n",
       "      <td>Kelly Havens is not inspirational. Her husband...</td>\n",
       "      <td>1</td>\n",
       "      <td>ED81029C263B8BA</td>\n",
       "      <td>2022-01-15T13:36:52-07:00</td>\n",
       "      <td>1494284839</td>\n",
       "      <td>simple-farmhouse-life</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/simple-f...</td>\n",
       "      <td>Simple Farmhouse Life</td>\n",
       "      <td>leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>bb7d6672764b565662154a695b9f0d64</td>\n",
       "      <td>More of this!</td>\n",
       "      <td>Marty brings out the best in everyone he inter...</td>\n",
       "      <td>5</td>\n",
       "      <td>ECF8AECAC5EE567</td>\n",
       "      <td>2018-08-25T04:51:04-07:00</td>\n",
       "      <td>1359891248</td>\n",
       "      <td>marty-smiths-america-the-podcast</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/marty-sm...</td>\n",
       "      <td>Marty Smith's America The Podcast</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             podcast_id  \\\n",
       "0      b313ef8ef0d5b64290d3036ff1bbf2d2   \n",
       "1      abfb842993be20d21bfae7103addc5e9   \n",
       "2      ebdf879a424547d01862a9bbba18a0f3   \n",
       "3      ab2fdb7db023b223d870487165d11ff3   \n",
       "4      ca601bd1524322d0527b16adf2738ff3   \n",
       "...                                 ...   \n",
       "49995  a0f4bdf8c437e34e5b6a17698fbdf64d   \n",
       "49996  d5683ccc88341197ca42aad82111c96f   \n",
       "49997  cc546886c2be6370d76bd638f5256ba6   \n",
       "49998  aaeb50f39da1a9a1d2e3837cf4edb2d0   \n",
       "49999  bb7d6672764b565662154a695b9f0d64   \n",
       "\n",
       "                                                   title  \\\n",
       "0                                            Í∞êÏÑ± ÎùºÎîîÏò§ ÏùåÏïÖÎèÑÏãú   \n",
       "1      They‚Äôve really cut back on the content this se...   \n",
       "2                                   Good info. source...   \n",
       "3                                                  Mixed   \n",
       "4                                            Try it now!   \n",
       "...                                                  ...   \n",
       "49995                                            üî•Sussyüî•   \n",
       "49996                              Jumping butterballs!!   \n",
       "49997                    Way too much junkie commercials   \n",
       "49998                                              Awful   \n",
       "49999                                      More of this!   \n",
       "\n",
       "                                                 content  rating  \\\n",
       "0      ÎØ∏Íµ≠ ÏÑúÎ∂ÄÏóê ÏûàÎäî Ïú†ÌïôÏÉùÏù¥ÏóêÏöî. ÏÑ±ÏãúÍ≤ΩÏî® Ï†úÎåÄ ÌõÑ ÎùºÎîîÏò§ Î≥µÍ∑ÄÎßå Í∏∞Îã§Î†§Ïò§Îã§Í∞Ä 6 Ïõî...       5   \n",
       "1      Last season there was a new pod every 3-4 days...       1   \n",
       "2      Bob brings a lot of knowledge to any firearm d...       4   \n",
       "3      They have lost much of thier credibility by de...       3   \n",
       "4      Even better than I expected. I was interested ...       5   \n",
       "...                                                  ...     ...   \n",
       "49995  A little bit $u$, make an episode on plant pol...       2   \n",
       "49996  If you are a Marx Brothers fan, and have been ...       5   \n",
       "49997  I love the show very interesting I‚Äôm telling t...       1   \n",
       "49998  Kelly Havens is not inspirational. Her husband...       1   \n",
       "49999  Marty brings out the best in everyone he inter...       5   \n",
       "\n",
       "             author_id                 created_at   itunes_id  \\\n",
       "0      664CCA7142E9AE8  2011-09-14T13:25:46-07:00   442838670   \n",
       "1      AD790CE113DCBC1  2018-04-11T13:46:47-07:00  1015394113   \n",
       "2      E223A4B2642C970  2010-01-19T08:11:43-07:00   333180229   \n",
       "3      E1E7DBE750D119E  2021-01-28T12:21:49-07:00   971901464   \n",
       "4      D7CA4858AFA2CFC  2017-08-24T10:55:20-07:00  1257821731   \n",
       "...                ...                        ...         ...   \n",
       "49995  45C72657925F18D  2022-03-28T07:16:21-07:00  1103320303   \n",
       "49996  AAF30F4EAE42219  2018-05-28T18:10:19-07:00  1363963113   \n",
       "49997  2032AE3B4B98F1F  2020-05-20T17:01:07-07:00  1484888427   \n",
       "49998  ED81029C263B8BA  2022-01-15T13:36:52-07:00  1494284839   \n",
       "49999  ECF8AECAC5EE567  2018-08-25T04:51:04-07:00  1359891248   \n",
       "\n",
       "                                                    slug  \\\n",
       "0      fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...   \n",
       "1         the-good-phight-for-philadelphia-phillies-fans   \n",
       "2                                  handgun-world-podcast   \n",
       "3                              wsj-opinion-potomac-watch   \n",
       "4                  conversations-with-people-who-hate-me   \n",
       "...                                                  ...   \n",
       "49995                 but-why-a-podcast-for-curious-kids   \n",
       "49996                  the-marx-brothers-council-podcast   \n",
       "49997                          autopsy-the-last-hours-of   \n",
       "49998                              simple-farmhouse-life   \n",
       "49999                   marty-smiths-america-the-podcast   \n",
       "\n",
       "                                              itunes_url  \\\n",
       "0      https://podcasts.apple.com/us/podcast/fm-%EC%9...   \n",
       "1      https://podcasts.apple.com/us/podcast/the-good...   \n",
       "2      https://podcasts.apple.com/us/podcast/handgun-...   \n",
       "3      https://podcasts.apple.com/us/podcast/wsj-opin...   \n",
       "4      https://podcasts.apple.com/us/podcast/conversa...   \n",
       "...                                                  ...   \n",
       "49995  https://podcasts.apple.com/us/podcast/but-why-...   \n",
       "49996  https://podcasts.apple.com/us/podcast/the-marx...   \n",
       "49997  https://podcasts.apple.com/us/podcast/autopsy-...   \n",
       "49998  https://podcasts.apple.com/us/podcast/simple-f...   \n",
       "49999  https://podcasts.apple.com/us/podcast/marty-sm...   \n",
       "\n",
       "                                         podcast_title category  \n",
       "0                                          FM ÏùåÏïÖÎèÑÏãú(Ï¢ÖÏòÅ)    music  \n",
       "1      The Good Phight: for Philadelphia Phillies fans   sports  \n",
       "2                                Handgun World Podcast     news  \n",
       "3                           WSJ Opinion: Potomac Watch     news  \n",
       "4                Conversations with People Who Hate Me  society  \n",
       "...                                                ...      ...  \n",
       "49995              But Why: A Podcast for Curious Kids     kids  \n",
       "49996                The Marx Brothers Council Podcast       tv  \n",
       "49997                      Autopsy: The Last Hours Of‚Ä¶  society  \n",
       "49998                            Simple Farmhouse Life  leisure  \n",
       "49999                Marty Smith's America The Podcast   sports  \n",
       "\n",
       "[50000 rows x 11 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('podcast_sample_new.csv', lineterminator='\\n', index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "92d4041a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>3783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>8019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>2988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiction</th>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history</th>\n",
       "      <td>1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids</th>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leisure</th>\n",
       "      <td>1726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>society</th>\n",
       "      <td>6445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>3589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tv</th>\n",
       "      <td>2177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "category         \n",
       "arts         3181\n",
       "business     3783\n",
       "comedy       8019\n",
       "crime        2521\n",
       "education    2988\n",
       "fiction       776\n",
       "government    413\n",
       "health       2353\n",
       "history      1417\n",
       "kids         1224\n",
       "leisure      1726\n",
       "music         891\n",
       "news         5206\n",
       "religion     2093\n",
       "science       820\n",
       "society      6445\n",
       "sports       3589\n",
       "technology    378\n",
       "tv           2177"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('category')['podcast_id'].agg({'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "14c30771",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = df[df['rating']<4]\n",
    "pos = df[df['rating']>=4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab56f1c9",
   "metadata": {},
   "source": [
    "### positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d7a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aldiz', 'baiknya', 'baizik', 'berkali', 'bukatzeko', 'edota', 'eze', 'ezpabere', 'ezpada', 'ezperen', 'gainera', 'gainerontzean', 'guztiz', 'hainbestez', 'horra', 'kali', 'kurangnya', 'mata', 'olah', 'ordea', 'osterantzean', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             max_df=0.4, max_features=1000, stop_words=stopwords.words())\n",
    "\n",
    "corpus = list(pos[\"content\"].values)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9accc51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c47e092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>love podcast</th>\n",
       "      <td>758.174728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great podcast</th>\n",
       "      <td>445.930163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love show</th>\n",
       "      <td>299.765015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listening podcast</th>\n",
       "      <td>270.720708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love listening</th>\n",
       "      <td>265.052220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great job</th>\n",
       "      <td>257.819878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>podcast great</th>\n",
       "      <td>252.988045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great work</th>\n",
       "      <td>249.873717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highly recommend</th>\n",
       "      <td>236.912586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great show</th>\n",
       "      <td>208.879908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listen podcast</th>\n",
       "      <td>207.269155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>podcast listen</th>\n",
       "      <td>200.711764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>podcast love</th>\n",
       "      <td>185.191296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favorite podcast</th>\n",
       "      <td>168.535074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started listening</th>\n",
       "      <td>166.492624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>found podcast</th>\n",
       "      <td>158.675376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love love</th>\n",
       "      <td>156.729245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun listen</th>\n",
       "      <td>151.078846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely love</th>\n",
       "      <td>143.666312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love guys</th>\n",
       "      <td>134.748582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy podcast</th>\n",
       "      <td>130.157693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great content</th>\n",
       "      <td>124.127447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy listening</th>\n",
       "      <td>117.809986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait hear</th>\n",
       "      <td>117.591729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long time</th>\n",
       "      <td>113.998129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great listen</th>\n",
       "      <td>112.293431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love hearing</th>\n",
       "      <td>107.259164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>show great</th>\n",
       "      <td>98.796748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy listen</th>\n",
       "      <td>97.845961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend podcast</th>\n",
       "      <td>97.110499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        score\n",
       "love podcast       758.174728\n",
       "great podcast      445.930163\n",
       "love show          299.765015\n",
       "listening podcast  270.720708\n",
       "love listening     265.052220\n",
       "great job          257.819878\n",
       "podcast great      252.988045\n",
       "great work         249.873717\n",
       "highly recommend   236.912586\n",
       "great show         208.879908\n",
       "listen podcast     207.269155\n",
       "podcast listen     200.711764\n",
       "podcast love       185.191296\n",
       "favorite podcast   168.535074\n",
       "started listening  166.492624\n",
       "found podcast      158.675376\n",
       "love love          156.729245\n",
       "fun listen         151.078846\n",
       "absolutely love    143.666312\n",
       "love guys          134.748582\n",
       "enjoy podcast      130.157693\n",
       "great content      124.127447\n",
       "enjoy listening    117.809986\n",
       "wait hear          117.591729\n",
       "long time          113.998129\n",
       "great listen       112.293431\n",
       "love hearing       107.259164\n",
       "show great          98.796748\n",
       "easy listen         97.845961\n",
       "recommend podcast   97.110499"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b2a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_STOP_WORDS = True\n",
    "STEMMING = False\n",
    "LEMMATIZE = True\n",
    "VECTORIZER = 'TFIDF' # TFIDF or COUNT\n",
    "NGRAM_SIZE = (2,2) # (1,1), (2,2), or (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2f08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ed9393d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantxt(cleanr):\n",
    "    cleanr = cleanr.strip().lower()\n",
    "    cleanr = re.sub(r'(podcasts?|listen|just|make|really|feel|need|don|love|year|week|great|job|work|pod|love love)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(love|like|great|good|really|really enojoy|true crime|started listening|listen|listening|new episode)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(look forward|looking forward|great work|great job|good job|good work|highly recommend)+(s?|es?)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(great work|great job|look forward|looking forward|good job|good work|great show|listened episode|feel like)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(favorite|absolutely|great|highly recommend|new|episode|love|enjoy|listen|listening|hard work|true crime)\\b',' ', cleanr)\n",
    "    \n",
    "    word_tokens = word_tokenize(cleanr)\n",
    "    \n",
    "    if REMOVE_STOP_WORDS == True:\n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "        filtered_sentence = []\n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        word_tokens = filtered_sentence\n",
    "    \n",
    "    if STEMMING == True:\n",
    "        word_tokens = [ps.stem(w) for w in word_tokens]\n",
    "        \n",
    "    if LEMMATIZE == True:\n",
    "        word_tokens = [lemmatizer.lemmatize(w) for w in word_tokens]\n",
    "        \n",
    "    output_text = ' '.join(word_tokens)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4df0ef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/z2gfj07x2s187jy3_c87nhj80000gq/T/ipykernel_2055/2783385914.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos['clean_content'] = pos.apply(lambda x: cleantxt(x['content']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "pos['clean_content'] = pos.apply(lambda x: cleantxt(x['content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "611f0e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aldiz', 'baiknya', 'baizik', 'berkali', 'bukatzeko', 'edota', 'eze', 'ezpabere', 'ezpada', 'ezperen', 'gainera', 'gainerontzean', 'guztiz', 'hainbestez', 'horra', 'kali', 'kurangnya', 'mata', 'olah', 'ordea', 'osterantzean', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>highly recommend</th>\n",
       "      <td>285.784880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started listening</th>\n",
       "      <td>191.314029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward episode</th>\n",
       "      <td>177.043222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listened episode</th>\n",
       "      <td>162.492897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy listening</th>\n",
       "      <td>134.594290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait hear</th>\n",
       "      <td>131.401650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long time</th>\n",
       "      <td>128.810358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait episode</th>\n",
       "      <td>108.775226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listening episode</th>\n",
       "      <td>107.998922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real life</th>\n",
       "      <td>99.400959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year ago</th>\n",
       "      <td>86.255098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>give star</th>\n",
       "      <td>85.720304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward hearing</th>\n",
       "      <td>84.223142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward listening</th>\n",
       "      <td>81.947460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop listening</th>\n",
       "      <td>79.652656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop culture</th>\n",
       "      <td>79.085460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glad found</th>\n",
       "      <td>73.733625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listening show</th>\n",
       "      <td>72.433990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listening guy</th>\n",
       "      <td>70.838004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highly recommended</th>\n",
       "      <td>68.868179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story telling</th>\n",
       "      <td>68.758338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social medium</th>\n",
       "      <td>65.685616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound quality</th>\n",
       "      <td>57.729886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month ago</th>\n",
       "      <td>57.264327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top notch</th>\n",
       "      <td>56.958643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interesting topic</th>\n",
       "      <td>56.783104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject matter</th>\n",
       "      <td>56.460393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high school</th>\n",
       "      <td>56.311245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point view</th>\n",
       "      <td>54.346153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>god bless</th>\n",
       "      <td>53.693051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         score\n",
       "highly recommend    285.784880\n",
       "started listening   191.314029\n",
       "forward episode     177.043222\n",
       "listened episode    162.492897\n",
       "enjoy listening     134.594290\n",
       "wait hear           131.401650\n",
       "long time           128.810358\n",
       "wait episode        108.775226\n",
       "listening episode   107.998922\n",
       "real life            99.400959\n",
       "year ago             86.255098\n",
       "give star            85.720304\n",
       "forward hearing      84.223142\n",
       "forward listening    81.947460\n",
       "stop listening       79.652656\n",
       "pop culture          79.085460\n",
       "glad found           73.733625\n",
       "listening show       72.433990\n",
       "listening guy        70.838004\n",
       "highly recommended   68.868179\n",
       "story telling        68.758338\n",
       "social medium        65.685616\n",
       "sound quality        57.729886\n",
       "month ago            57.264327\n",
       "top notch            56.958643\n",
       "interesting topic    56.783104\n",
       "subject matter       56.460393\n",
       "high school          56.311245\n",
       "point view           54.346153\n",
       "god bless            53.693051"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score again \n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             max_df=0.4, max_features=1000, stop_words=stopwords.words())\n",
    "\n",
    "corpus = list(pos[\"clean_content\"].values)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "score.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1d241674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podcast Review TF-IDF: (28249, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highly recommend</th>\n",
       "      <th>look forward</th>\n",
       "      <th>looking forward</th>\n",
       "      <th>new episode</th>\n",
       "      <th>started listening</th>\n",
       "      <th>true crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   highly recommend  look forward  looking forward  new episode  \\\n",
       "0               0.0           0.0              0.0          0.0   \n",
       "1               0.0           0.0              0.0          0.0   \n",
       "2               0.0           0.0              0.0          0.0   \n",
       "3               0.0           0.0              0.0          0.0   \n",
       "4               0.0           0.0              0.0          0.0   \n",
       "\n",
       "   started listening  true crime  \n",
       "0                0.0         0.0  \n",
       "1                0.0         0.0  \n",
       "2                0.0         0.0  \n",
       "3                0.0         0.0  \n",
       "4                0.0         0.0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             min_df=0.01, max_df=0.6, stop_words=\"english\")\n",
    "\n",
    "\n",
    "X_review1, review_terms1 = vectorizer1.fit_transform(pos.clean_content), vectorizer1.get_feature_names_out()\n",
    "review_tf_idf1 = pd.DataFrame(X_review1.toarray(), columns=review_terms1)\n",
    "print(f\"Podcast Review TF-IDF: {review_tf_idf1.shape}\")\n",
    "review_tf_idf1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "144c770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of X review is (28249, 6)\n",
      "Decomposed W review matrix is (28249, 3)\n",
      "Decomposed H review matrix is (3, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nmf1 = NMF(n_components=3)\n",
    "W_review1 = nmf1.fit_transform(X_review1)\n",
    "H_review1 = nmf1.components_\n",
    "print(f\"Original shape of X review is {X_review1.shape}\")\n",
    "print(f\"Decomposed W review matrix is {W_review1.shape}\")\n",
    "print(f\"Decomposed H review matrix is {H_review1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dd63fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def get_top_tf_idf_tokens_for_topic(H: np.array, feature_names: List[str], num_top_tokens: int = 5):\n",
    "  \"\"\"\n",
    "  Uses the H matrix (K components x M original features) to identify for each\n",
    "  topic the most frequent tokens.\n",
    "  \"\"\"\n",
    "  for topic, vector in enumerate(H):\n",
    "    print(f\"TOPIC {topic}\\n\")\n",
    "    total = vector.sum()\n",
    "    top_scores = vector.argsort()[::-1][:num_top_tokens]\n",
    "    token_names = list(map(lambda idx: feature_names[idx], top_scores))\n",
    "    strengths = list(map(lambda idx: vector[idx] / total, top_scores))\n",
    "    \n",
    "    for strength, token_name in zip(strengths, token_names):\n",
    "          print(f\"\\b{token_name} ({round(strength * 100, 1)}%)\\n\")\n",
    "    print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4032462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "\n",
      "\blook forward (87.0%)\n",
      "\n",
      "\bnew episode (10.7%)\n",
      "\n",
      "\bstarted listening (1.2%)\n",
      "\n",
      "\btrue crime (1.1%)\n",
      "\n",
      "\blooking forward (0.0%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 1\n",
      "\n",
      "\bhighly recommend (95.4%)\n",
      "\n",
      "\bstarted listening (4.0%)\n",
      "\n",
      "\btrue crime (0.5%)\n",
      "\n",
      "\bnew episode (0.1%)\n",
      "\n",
      "\blooking forward (0.0%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 2\n",
      "\n",
      "\blooking forward (90.7%)\n",
      "\n",
      "\bnew episode (7.2%)\n",
      "\n",
      "\bstarted listening (1.8%)\n",
      "\n",
      "\btrue crime (0.2%)\n",
      "\n",
      "\blook forward (0.0%)\n",
      "\n",
      "==================================================\n",
      "Podcast Review Topics:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_top_tf_idf_tokens_for_topic(H_review1, review_tf_idf1.columns.tolist(), 5)\n",
    "print(f\"Podcast Review Topics:\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80199e41",
   "metadata": {},
   "source": [
    "### negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "26da5ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aldiz', 'baiknya', 'baizik', 'berkali', 'bukatzeko', 'edota', 'eze', 'ezpabere', 'ezpada', 'ezperen', 'gainera', 'gainerontzean', 'guztiz', 'hainbestez', 'horra', 'kali', 'kurangnya', 'mata', 'olah', 'ordea', 'osterantzean', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             max_df=0.4, max_features=1000, stop_words=stopwords.words())\n",
    "\n",
    "corpus = list(neg[\"content\"].values)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1c22f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9afd1f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>waste time</th>\n",
       "      <td>221.780865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love podcast</th>\n",
       "      <td>211.911576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard listen</th>\n",
       "      <td>155.024631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   score\n",
       "waste time    221.780865\n",
       "love podcast  211.911576\n",
       "hard listen   155.024631"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07155912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_replace(line):\n",
    "    line = re.sub(r'\\b(podcasts?|listen|just|really|don|like|lot|use|want|say|episode)\\b', '', line)\n",
    "    line = re.sub(r'\\b(make|think|minute|love|pods?|good|year)\\b', '', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e778e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantxt(cleanr):\n",
    "    cleanr = cleanr.strip().lower()\n",
    "    cleanr = re.sub(r'\\b(podcasts?|listen|just|really|don|like|lot|use|want|say|episode)\\b',' ', cleanr)\n",
    "    cleanr = re.sub(r'\\b(make|think|minute|love|pods?|good|year)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(love|like|great|good|really|really enojoy|true crime|started listening|listen|listening|new episode)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(look forward|looking forward|great work|great job|good job|good work|highly recommend)+(s?|es?)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(great work|great job|look forward|looking forward|good job|good work|great show|listened episode|feel like)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(favorite|absolutely|great|highly recommend|new|episode|love|enjoy|listen|listening|hard work|true crime)\\b',' ', cleanr)\n",
    "    \n",
    "    word_tokens = word_tokenize(cleanr)\n",
    "    \n",
    "    if REMOVE_STOP_WORDS == True:\n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "        filtered_sentence = []\n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        word_tokens = filtered_sentence\n",
    "    \n",
    "    if STEMMING == True:\n",
    "        word_tokens = [ps.stem(w) for w in word_tokens]\n",
    "        \n",
    "    if LEMMATIZE == True:\n",
    "        word_tokens = [lemmatizer.lemmatize(w) for w in word_tokens]\n",
    "        \n",
    "    output_text = ' '.join(word_tokens)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7546462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/z2gfj07x2s187jy3_c87nhj80000gq/T/ipykernel_2055/2175117729.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg['clean_content'] = neg.apply(lambda x: cleantxt(x['content']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "neg['clean_content'] = neg.apply(lambda x: cleantxt(x['content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "03329d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aldiz', 'baiknya', 'baizik', 'berkali', 'bukatzeko', 'edota', 'eze', 'ezpabere', 'ezpada', 'ezperen', 'gainera', 'gainerontzean', 'guztiz', 'hainbestez', 'horra', 'kali', 'kurangnya', 'mata', 'olah', 'ordea', 'osterantzean', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>waste time</th>\n",
       "      <td>242.263745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long time</th>\n",
       "      <td>108.694448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop listening</th>\n",
       "      <td>105.166790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>give star</th>\n",
       "      <td>87.640237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started listening</th>\n",
       "      <td>87.280937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound quality</th>\n",
       "      <td>86.148968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject matter</th>\n",
       "      <td>82.630875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listened episode</th>\n",
       "      <td>79.688357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring back</th>\n",
       "      <td>78.889662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopped listening</th>\n",
       "      <td>75.864706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio quality</th>\n",
       "      <td>71.367930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point view</th>\n",
       "      <td>66.769088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high school</th>\n",
       "      <td>66.116708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime junkie</th>\n",
       "      <td>63.571537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social medium</th>\n",
       "      <td>62.830501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story telling</th>\n",
       "      <td>62.510616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spend time</th>\n",
       "      <td>61.942566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast forward</th>\n",
       "      <td>60.914510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time listening</th>\n",
       "      <td>60.909704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star review</th>\n",
       "      <td>60.523365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year ago</th>\n",
       "      <td>60.160483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interesting story</th>\n",
       "      <td>59.941235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great show</th>\n",
       "      <td>59.427079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political view</th>\n",
       "      <td>58.407960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocal fry</th>\n",
       "      <td>56.612133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>show great</th>\n",
       "      <td>50.751353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great content</th>\n",
       "      <td>50.429427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound effect</th>\n",
       "      <td>49.627548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>live show</th>\n",
       "      <td>48.752305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story interesting</th>\n",
       "      <td>48.343081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        score\n",
       "waste time         242.263745\n",
       "long time          108.694448\n",
       "stop listening     105.166790\n",
       "give star           87.640237\n",
       "started listening   87.280937\n",
       "sound quality       86.148968\n",
       "subject matter      82.630875\n",
       "listened episode    79.688357\n",
       "bring back          78.889662\n",
       "stopped listening   75.864706\n",
       "audio quality       71.367930\n",
       "point view          66.769088\n",
       "high school         66.116708\n",
       "crime junkie        63.571537\n",
       "social medium       62.830501\n",
       "story telling       62.510616\n",
       "spend time          61.942566\n",
       "fast forward        60.914510\n",
       "time listening      60.909704\n",
       "star review         60.523365\n",
       "year ago            60.160483\n",
       "interesting story   59.941235\n",
       "great show          59.427079\n",
       "political view      58.407960\n",
       "vocal fry           56.612133\n",
       "show great          50.751353\n",
       "great content       50.429427\n",
       "sound effect        49.627548\n",
       "live show           48.752305\n",
       "story interesting   48.343081"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score again \n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             max_df=0.4, max_features=1000, stop_words=stopwords.words())\n",
    "\n",
    "corpus = list(neg[\"clean_content\"].values)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "score.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "051e9f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podcast Review TF-IDF: (21751, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true crime</th>\n",
       "      <th>waste time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true crime  waste time\n",
       "0         0.0         0.0\n",
       "1         0.0         0.0\n",
       "2         0.0         0.0\n",
       "3         0.0         0.0\n",
       "4         0.0         0.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             min_df=0.01, max_df=0.6, stop_words=\"english\")\n",
    "\n",
    "\n",
    "X_review1, review_terms1 = vectorizer1.fit_transform(neg.clean_content), vectorizer1.get_feature_names_out()\n",
    "review_tf_idf1 = pd.DataFrame(X_review1.toarray(), columns=review_terms1)\n",
    "print(f\"Podcast Review TF-IDF: {review_tf_idf1.shape}\")\n",
    "review_tf_idf1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ce5622f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of X review is (21751, 2)\n",
      "Decomposed W review matrix is (21751, 3)\n",
      "Decomposed H review matrix is (3, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nmf1 = NMF(n_components=3)\n",
    "W_review1 = nmf1.fit_transform(X_review1)\n",
    "H_review1 = nmf1.components_\n",
    "print(f\"Original shape of X review is {X_review1.shape}\")\n",
    "print(f\"Decomposed W review matrix is {W_review1.shape}\")\n",
    "print(f\"Decomposed H review matrix is {H_review1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a8ead4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def get_top_tf_idf_tokens_for_topic(H: np.array, feature_names: List[str], num_top_tokens: int = 5):\n",
    "  \"\"\"\n",
    "  Uses the H matrix (K components x M original features) to identify for each\n",
    "  topic the most frequent tokens.\n",
    "  \"\"\"\n",
    "  for topic, vector in enumerate(H):\n",
    "    print(f\"TOPIC {topic}\\n\")\n",
    "    total = vector.sum()\n",
    "    top_scores = vector.argsort()[::-1][:num_top_tokens]\n",
    "    token_names = list(map(lambda idx: feature_names[idx], top_scores))\n",
    "    strengths = list(map(lambda idx: vector[idx] / total, top_scores))\n",
    "    \n",
    "    for strength, token_name in zip(strengths, token_names):\n",
    "          print(f\"\\b{token_name} ({round(strength * 100, 1)}%)\\n\")\n",
    "    print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9d0530fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "\n",
      "\bwaste time (100.0%)\n",
      "\n",
      "\btrue crime (0.0%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 1\n",
      "\n",
      "\btrue crime (100.0%)\n",
      "\n",
      "\bwaste time (0.0%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 2\n",
      "\n",
      "\btrue crime (100.0%)\n",
      "\n",
      "\bwaste time (0.0%)\n",
      "\n",
      "==================================================\n",
      "Podcast Review Topics:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_top_tf_idf_tokens_for_topic(H_review1, review_tf_idf1.columns.tolist(), 5)\n",
    "print(f\"Podcast Review Topics:\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b0595",
   "metadata": {},
   "source": [
    "### negative: news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ff2a1d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_news = df[(df['rating']<4)&(df['category']=='news')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a1ebefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aldiz', 'baiknya', 'baizik', 'berkali', 'bukatzeko', 'edota', 'eze', 'ezpabere', 'ezpada', 'ezperen', 'gainera', 'gainerontzean', 'guztiz', 'hainbestez', 'horra', 'kali', 'kurangnya', 'mata', 'olah', 'ordea', 'osterantzean', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>waste time</th>\n",
       "      <td>29.478363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listen podcast</th>\n",
       "      <td>22.960849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left wing</th>\n",
       "      <td>17.882479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long time</th>\n",
       "      <td>17.436235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talking points</th>\n",
       "      <td>13.845068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point view</th>\n",
       "      <td>12.828270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love show</th>\n",
       "      <td>12.752025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listen show</th>\n",
       "      <td>12.496078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox news</th>\n",
       "      <td>12.379474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love podcast</th>\n",
       "      <td>12.232290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring back</th>\n",
       "      <td>11.519657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake news</th>\n",
       "      <td>11.500712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listening podcast</th>\n",
       "      <td>11.074417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listened podcast</th>\n",
       "      <td>11.041950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard listen</th>\n",
       "      <td>10.848508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopped listening</th>\n",
       "      <td>10.568492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop listening</th>\n",
       "      <td>10.510353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>give stars</th>\n",
       "      <td>10.421861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recent episode</th>\n",
       "      <td>10.150957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>podcast listen</th>\n",
       "      <td>9.813115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>democratic party</th>\n",
       "      <td>9.683270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>echo chamber</th>\n",
       "      <td>9.509331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocal fry</th>\n",
       "      <td>9.374105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy podcast</th>\n",
       "      <td>9.279864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high school</th>\n",
       "      <td>8.698785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time listener</th>\n",
       "      <td>8.437973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe biden</th>\n",
       "      <td>8.330750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left leaning</th>\n",
       "      <td>8.149513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current events</th>\n",
       "      <td>7.549880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full show</th>\n",
       "      <td>7.497904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score\n",
       "waste time         29.478363\n",
       "listen podcast     22.960849\n",
       "left wing          17.882479\n",
       "long time          17.436235\n",
       "talking points     13.845068\n",
       "point view         12.828270\n",
       "love show          12.752025\n",
       "listen show        12.496078\n",
       "fox news           12.379474\n",
       "love podcast       12.232290\n",
       "bring back         11.519657\n",
       "fake news          11.500712\n",
       "listening podcast  11.074417\n",
       "listened podcast   11.041950\n",
       "hard listen        10.848508\n",
       "stopped listening  10.568492\n",
       "stop listening     10.510353\n",
       "give stars         10.421861\n",
       "recent episode     10.150957\n",
       "podcast listen      9.813115\n",
       "democratic party    9.683270\n",
       "echo chamber        9.509331\n",
       "vocal fry           9.374105\n",
       "enjoy podcast       9.279864\n",
       "high school         8.698785\n",
       "time listener       8.437973\n",
       "joe biden           8.330750\n",
       "left leaning        8.149513\n",
       "current events      7.549880\n",
       "full show           7.497904"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             max_df=0.4, max_features=1000, stop_words=stopwords.words())\n",
    "\n",
    "corpus = list(neg_news[\"content\"].values)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "score.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c37495d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantxt(cleanr):\n",
    "    cleanr = cleanr.strip().lower()\n",
    "    cleanr = re.sub(r'\\b(podcast|show)+(s?|es?)\\b',' ', cleanr)\n",
    "    cleanr = re.sub(r'\\b(waste time|feel like|true crime|sound like)\\b',' ', cleanr)\n",
    "    cleanr = re.sub(r'\\b(listen|listening|stop|stopped|love)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(love|like|great|good|really|really enojoy|true crime|started listening|listen|listening|new episode)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(look forward|looking forward|great work|great job|good job|good work|highly recommend)+(s?|es?)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(great work|great job|look forward|looking forward|good job|good work|great show|listened episode|feel like)\\b',' ', cleanr)\n",
    "#     cleanr = re.sub(r'\\b(favorite|absolutely|great|highly recommend|new|episode|love|enjoy|listen|listening|hard work|true crime)\\b',' ', cleanr)\n",
    "    \n",
    "    word_tokens = word_tokenize(cleanr)\n",
    "    \n",
    "    if REMOVE_STOP_WORDS == True:\n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "        filtered_sentence = []\n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        word_tokens = filtered_sentence\n",
    "    \n",
    "    if STEMMING == True:\n",
    "        word_tokens = [ps.stem(w) for w in word_tokens]\n",
    "        \n",
    "    if LEMMATIZE == True:\n",
    "        word_tokens = [lemmatizer.lemmatize(w) for w in word_tokens]\n",
    "        \n",
    "    output_text = ' '.join(word_tokens)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6576d71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/z2gfj07x2s187jy3_c87nhj80000gq/T/ipykernel_2055/79664435.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_news['clean_content'] = neg_news.apply(lambda x: cleantxt(x['content']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "neg_news['clean_content'] = neg_news.apply(lambda x: cleantxt(x['content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c269f973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podcast Review TF-IDF: (3202, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ben shapiro</th>\n",
       "      <th>point view</th>\n",
       "      <th>sound like</th>\n",
       "      <th>waste time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ben shapiro  point view  sound like  waste time\n",
       "0          0.0         0.0         0.0         0.0\n",
       "1          1.0         0.0         0.0         0.0\n",
       "2          0.0         0.0         0.0         0.0\n",
       "3          0.0         0.0         0.0         0.0\n",
       "4          0.0         0.0         0.0         0.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             min_df=0.01, max_df=0.4, stop_words=\"english\")\n",
    "\n",
    "\n",
    "X_review1, review_terms1 = vectorizer1.fit_transform(neg_news.clean_content), vectorizer1.get_feature_names_out()\n",
    "review_tf_idf1 = pd.DataFrame(X_review1.toarray(), columns=review_terms1)\n",
    "print(f\"Podcast Review TF-IDF: {review_tf_idf1.shape}\")\n",
    "review_tf_idf1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9c5ad45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of X review is (3202, 4)\n",
      "Decomposed W review matrix is (3202, 3)\n",
      "Decomposed H review matrix is (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nmf1 = NMF(n_components=3)\n",
    "W_review1 = nmf1.fit_transform(X_review1)\n",
    "H_review1 = nmf1.components_\n",
    "print(f\"Original shape of X review is {X_review1.shape}\")\n",
    "print(f\"Decomposed W review matrix is {W_review1.shape}\")\n",
    "print(f\"Decomposed H review matrix is {H_review1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "adfb0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def get_top_tf_idf_tokens_for_topic(H: np.array, feature_names: List[str], num_top_tokens: int = 5):\n",
    "  \"\"\"\n",
    "  Uses the H matrix (K components x M original features) to identify for each\n",
    "  topic the most frequent tokens.\n",
    "  \"\"\"\n",
    "  for topic, vector in enumerate(H):\n",
    "    print(f\"TOPIC {topic}\\n\")\n",
    "    total = vector.sum()\n",
    "    top_scores = vector.argsort()[::-1][:num_top_tokens]\n",
    "    token_names = list(map(lambda idx: feature_names[idx], top_scores))\n",
    "    strengths = list(map(lambda idx: vector[idx] / total, top_scores))\n",
    "    \n",
    "    for strength, token_name in zip(strengths, token_names):\n",
    "          print(f\"\\b{token_name} ({round(strength * 100, 1)}%)\\n\")\n",
    "    print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b0899d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "\n",
      "\bsound like (100.0%)\n",
      "\n",
      "\bwaste time (0.0%)\n",
      "\n",
      "\bpoint view (0.0%)\n",
      "\n",
      "\bben shapiro (0.0%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 1\n",
      "\n",
      "\bwaste time (96.0%)\n",
      "\n",
      "\bpoint view (4.0%)\n",
      "\n",
      "\bsound like (0.0%)\n",
      "\n",
      "\bben shapiro (0.0%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 2\n",
      "\n",
      "\bben shapiro (100.0%)\n",
      "\n",
      "\bwaste time (0.0%)\n",
      "\n",
      "\bsound like (0.0%)\n",
      "\n",
      "\bpoint view (0.0%)\n",
      "\n",
      "==================================================\n",
      "Podcast Review Topics:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_top_tf_idf_tokens_for_topic(H_review1, review_tf_idf1.columns.tolist(), 5)\n",
    "print(f\"Podcast Review Topics:\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fcf4c",
   "metadata": {},
   "source": [
    "### negative: health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3f9ddc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_health = df[(df['rating']<4)&(df['category']=='health')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a77dd5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/z2gfj07x2s187jy3_c87nhj80000gq/T/ipykernel_2055/3074378791.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_health['clean_content'] = neg_health.apply(lambda x: cleantxt(x['content']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "neg_health['clean_content'] = neg_health.apply(lambda x: cleantxt(x['content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "31952419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podcast Review TF-IDF: (652, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio quality</th>\n",
       "      <th>episode listened</th>\n",
       "      <th>felt like</th>\n",
       "      <th>hard time</th>\n",
       "      <th>listened episode</th>\n",
       "      <th>listening episode</th>\n",
       "      <th>long time</th>\n",
       "      <th>sound like</th>\n",
       "      <th>sound quality</th>\n",
       "      <th>started listening</th>\n",
       "      <th>stop listening</th>\n",
       "      <th>want hear</th>\n",
       "      <th>waste time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   audio quality  episode listened  felt like  hard time  listened episode  \\\n",
       "0            0.0               0.0        0.0        0.0               0.0   \n",
       "1            0.0               0.0        0.0        0.0               0.0   \n",
       "2            0.0               0.0        0.0        0.0               0.0   \n",
       "3            0.0               0.0        0.0        1.0               0.0   \n",
       "4            0.0               0.0        0.0        0.0               0.0   \n",
       "\n",
       "   listening episode  long time  sound like  sound quality  started listening  \\\n",
       "0                0.0        0.0         0.0            0.0                0.0   \n",
       "1                0.0        0.0         0.0            0.0                0.0   \n",
       "2                0.0        0.0         0.0            0.0                0.0   \n",
       "3                0.0        0.0         0.0            0.0                0.0   \n",
       "4                0.0        0.0         0.0            0.0                0.0   \n",
       "\n",
       "   stop listening  want hear  waste time  \n",
       "0             0.0        0.0         0.0  \n",
       "1             0.0        0.0         0.0  \n",
       "2             0.0        0.0         0.0  \n",
       "3             0.0        0.0         0.0  \n",
       "4             0.0        0.0         0.0  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             min_df=0.01, max_df=0.4, stop_words=\"english\")\n",
    "\n",
    "\n",
    "X_review1, review_terms1 = vectorizer1.fit_transform(neg_health.clean_content), vectorizer1.get_feature_names_out()\n",
    "review_tf_idf1 = pd.DataFrame(X_review1.toarray(), columns=review_terms1)\n",
    "print(f\"Podcast Review TF-IDF: {review_tf_idf1.shape}\")\n",
    "review_tf_idf1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "93ba62e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of X review is (652, 13)\n",
      "Decomposed W review matrix is (652, 3)\n",
      "Decomposed H review matrix is (3, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nmf1 = NMF(n_components=3)\n",
    "W_review1 = nmf1.fit_transform(X_review1)\n",
    "H_review1 = nmf1.components_\n",
    "print(f\"Original shape of X review is {X_review1.shape}\")\n",
    "print(f\"Decomposed W review matrix is {W_review1.shape}\")\n",
    "print(f\"Decomposed H review matrix is {H_review1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "34a76ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "\n",
      "\bsound like (96.7%)\n",
      "\n",
      "\bsound quality (3.1%)\n",
      "\n",
      "\baudio quality (0.2%)\n",
      "\n",
      "\bwant hear (0.1%)\n",
      "\n",
      "\bwaste time (0.0%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 1\n",
      "\n",
      "\bstop listening (76.8%)\n",
      "\n",
      "\blong time (15.0%)\n",
      "\n",
      "\bstarted listening (7.6%)\n",
      "\n",
      "\blistening episode (0.6%)\n",
      "\n",
      "\bepisode listened (0.0%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 2\n",
      "\n",
      "\blistened episode (100.0%)\n",
      "\n",
      "\bwaste time (0.0%)\n",
      "\n",
      "\bwant hear (0.0%)\n",
      "\n",
      "\bstop listening (0.0%)\n",
      "\n",
      "\bstarted listening (0.0%)\n",
      "\n",
      "==================================================\n",
      "Podcast Review Topics:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_top_tf_idf_tokens_for_topic(H_review1, review_tf_idf1.columns.tolist(), 5)\n",
    "print(f\"Podcast Review Topics:\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d6099",
   "metadata": {},
   "source": [
    "### negative: science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c28486c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_science = df[(df['rating']<4)&(df['category']=='science')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c0bd29b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/z2gfj07x2s187jy3_c87nhj80000gq/T/ipykernel_2055/1949001041.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_science['clean_content'] = neg_science.apply(lambda x: cleantxt(x['content']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "neg_science['clean_content'] = neg_science.apply(lambda x: cleantxt(x['content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5631fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             min_df=0.01, max_df=0.4, stop_words=\"english\")\n",
    "\n",
    "\n",
    "X_review1, review_terms1 = vectorizer1.fit_transform(neg_health.clean_content), vectorizer1.get_feature_names_out()\n",
    "review_tf_idf1 = pd.DataFrame(X_review1.toarray(), columns=review_terms1)\n",
    "print(f\"Podcast Review TF-IDF: {review_tf_idf1.shape}\")\n",
    "review_tf_idf1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b695f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261e5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "757ee7b5",
   "metadata": {},
   "source": [
    "### Genism & LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8b154dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d7dd95b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Last season there was a new pod every 3-4 days when the season started. Now '\n",
      " '2 weeks into the season and there are only 2 pods in that time.  Time to '\n",
      " 'start shopping for a new Phillies podcast.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:6: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:4: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:6: DeprecationWarning: invalid escape sequence \\d\n",
      "/var/folders/zy/z2gfj07x2s187jy3_c87nhj80000gq/T/ipykernel_2055/3176144363.py:4: DeprecationWarning: invalid escape sequence \\d\n",
      "  data = [re.sub('\\d(podcast|show)+(s?|es?)\\d', '', cleanr) for cleanr in data]\n",
      "/var/folders/zy/z2gfj07x2s187jy3_c87nhj80000gq/T/ipykernel_2055/3176144363.py:6: DeprecationWarning: invalid escape sequence \\d\n",
      "  data = [re.sub('\\d(true crime|waste time|sound like|point view)\\d', ' ', cleanr) for cleanr in data]\n"
     ]
    }
   ],
   "source": [
    "# Convert to list \n",
    "data = neg.content.values.tolist()  \n",
    "# Remove Emails \n",
    "data = [re.sub('\\d(podcast|show)+(s?|es?)\\d', '', cleanr) for cleanr in data]  \n",
    "# Remove new line characters \n",
    "data = [re.sub('\\d(true crime|waste time|sound like|point view)\\d', ' ', cleanr) for cleanr in data]  \n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8f7f4f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['last', 'season', 'there', 'was', 'new', 'pod', 'every', 'days', 'when', 'the', 'season', 'started', 'now', 'weeks', 'into', 'the', 'season', 'and', 'there', 'are', 'only', 'pods', 'in', 'that', 'time', 'time', 'to', 'start', 'shopping', 'for', 'new', 'phillies', 'podcast']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  #deacc=True removes punctuations\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0ab6a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last', 'season', 'there', 'was', 'new', 'pod', 'every', 'days', 'when', 'the', 'season', 'started', 'now', 'weeks', 'into', 'the', 'season', 'and', 'there', 'are', 'only', 'pods', 'in', 'that', 'time', 'time', 'to', 'start', 'shopping', 'for', 'new', 'phillies', 'podcast']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "674bc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "38f77121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['last', 'season', 'new', 'pod', 'day', 'season', 'start', 'week', 'season', 'pod', 'time', 'time', 'start', 'shop', 'new', 'phillie', 'podcast']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f890f042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 2), (5, 1), (6, 3), (7, 1), (8, 2), (9, 2), (10, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary \n",
    "id2word = corpora.Dictionary(data_lemmatized)  \n",
    "# Create Corpus \n",
    "texts = data_lemmatized  \n",
    "# Term Document Frequency \n",
    "corpus = [id2word.doc2bow(text) for text in texts]  \n",
    "# View \n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0149ab8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('day', 1),\n",
       "  ('last', 1),\n",
       "  ('new', 2),\n",
       "  ('phillie', 1),\n",
       "  ('pod', 2),\n",
       "  ('podcast', 1),\n",
       "  ('season', 3),\n",
       "  ('shop', 1),\n",
       "  ('start', 2),\n",
       "  ('time', 2),\n",
       "  ('week', 1)]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "43330d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5f2c50c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.077*\"show\" + 0.035*\"host\" + 0.019*\"new\" + 0.017*\"see\" + 0.014*\"interview\" '\n",
      "  '+ 0.010*\"issue\" + 0.010*\"old\" + 0.009*\"become\" + 0.008*\"season\" + '\n",
      "  '0.008*\"far\"'),\n",
      " (1,\n",
      "  '0.049*\"podcast\" + 0.033*\"listen\" + 0.024*\"get\" + 0.016*\"time\" + '\n",
      "  '0.016*\"make\" + 0.014*\"talk\" + 0.014*\"really\" + 0.014*\"good\" + 0.014*\"say\" + '\n",
      "  '0.014*\"go\"'),\n",
      " (2,\n",
      "  '0.018*\"people\" + 0.014*\"life\" + 0.014*\"right\" + 0.012*\"question\" + '\n",
      "  '0.011*\"believe\" + 0.009*\"fun\" + 0.009*\"learn\" + 0.008*\"help\" + '\n",
      "  '0.008*\"world\" + 0.008*\"ask\"'),\n",
      " (3,\n",
      "  '0.036*\"woman\" + 0.032*\"man\" + 0.017*\"audio\" + 0.016*\"trump\" + 0.014*\"movie\" '\n",
      "  '+ 0.012*\"kid\" + 0.011*\"quite\" + 0.011*\"entire\" + 0.009*\"claim\" + '\n",
      "  '0.009*\"medium\"'),\n",
      " (4,\n",
      "  '0.075*\"episode\" + 0.028*\"guest\" + 0.021*\"first\" + 0.018*\"minute\" + '\n",
      "  '0.017*\"come\" + 0.016*\"topic\" + 0.015*\"interesting\" + 0.015*\"year\" + '\n",
      "  '0.015*\"back\" + 0.014*\"ad\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the keyword of topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a9650a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/en-ning.chiang/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el20551404057676337125852239420\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el20551404057676337125852239420_data = {\"mdsDat\": {\"x\": [0.41496948681509427, -0.08252198471840502, -0.10254612949615616, -0.10010713005697294, -0.1297942425435604], \"y\": [0.014702786297051289, -0.35270501156651257, 0.2487761122415675, 0.06349347444455085, 0.025732638583342664], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [50.46538013895986, 16.084382010790087, 15.259310075694641, 12.511045905462339, 5.6798818690930775]}, \"tinfo\": {\"Term\": [\"show\", \"episode\", \"podcast\", \"listen\", \"host\", \"get\", \"guest\", \"people\", \"first\", \"woman\", \"time\", \"make\", \"new\", \"man\", \"minute\", \"come\", \"talk\", \"really\", \"see\", \"good\", \"topic\", \"say\", \"go\", \"interesting\", \"year\", \"back\", \"ad\", \"story\", \"interview\", \"much\", \"podcast\", \"listen\", \"get\", \"time\", \"make\", \"talk\", \"really\", \"good\", \"say\", \"story\", \"much\", \"love\", \"think\", \"hear\", \"well\", \"know\", \"want\", \"try\", \"great\", \"way\", \"feel\", \"guy\", \"thing\", \"give\", \"need\", \"bad\", \"find\", \"also\", \"use\", \"sound\", \"go\", \"even\", \"take\", \"seem\", \"people\", \"guest\", \"minute\", \"episode\", \"topic\", \"interesting\", \"year\", \"ad\", \"little\", \"information\", \"last\", \"day\", \"understand\", \"call\", \"mean\", \"less\", \"first\", \"hope\", \"bit\", \"case\", \"conversation\", \"quality\", \"different\", \"least\", \"discussion\", \"rather\", \"disappoint\", \"base\", \"unfortunately\", \"recent\", \"move\", \"back\", \"come\", \"end\", \"fact\", \"show\", \"see\", \"interview\", \"issue\", \"old\", \"season\", \"far\", \"miss\", \"hour\", \"joke\", \"view\", \"pod\", \"begin\", \"other\", \"completely\", \"discuss\", \"side\", \"watch\", \"politic\", \"lack\", \"sad\", \"mention\", \"laugh\", \"check\", \"absolutely\", \"pay\", \"horrible\", \"family\", \"cover\", \"able\", \"new\", \"host\", \"become\", \"life\", \"right\", \"question\", \"believe\", \"fun\", \"learn\", \"help\", \"ask\", \"world\", \"support\", \"else\", \"book\", \"guess\", \"child\", \"money\", \"narrator\", \"sorry\", \"act\", \"answer\", \"history\", \"country\", \"recommend\", \"racist\", \"important\", \"thank\", \"character\", \"mostly\", \"otherwise\", \"type\", \"victim\", \"wrong\", \"people\", \"live\", \"fact\", \"woman\", \"man\", \"audio\", \"trump\", \"movie\", \"kid\", \"quite\", \"entire\", \"claim\", \"medium\", \"yet\", \"today\", \"community\", \"tired\", \"buy\", \"free\", \"sentence\", \"lie\", \"honest\", \"relationship\", \"talking\", \"disagree\", \"title\", \"frustrating\", \"parent\", \"suffer\", \"line\", \"form\", \"helpful\", \"agenda\"], \"Freq\": [5847.0, 5992.0, 12335.0, 8213.0, 3028.0, 6026.0, 2208.0, 3210.0, 1693.0, 1026.0, 4042.0, 4003.0, 1429.0, 918.0, 1438.0, 1505.0, 3582.0, 3537.0, 1275.0, 3525.0, 1300.0, 3470.0, 3469.0, 1213.0, 1189.0, 1191.0, 1150.0, 3060.0, 1059.0, 2847.0, 12334.44214386525, 8213.023546841654, 6026.061756124212, 4041.5468487171097, 4002.300449734749, 3581.840392100317, 3536.8770459852994, 3524.5384646460525, 3470.142132318588, 3059.3649692720405, 2846.728341554214, 2781.057531185917, 2760.621308949881, 2760.6794489846916, 2583.6828970415795, 2467.878262865706, 2462.678715155741, 2456.4560903816036, 2437.9195000087643, 2349.8553988132962, 2188.086143971286, 2030.3873948729126, 2018.4353978780337, 1981.141144338699, 1873.8428895704728, 1864.8668183896652, 1813.5657396090094, 1641.0741026212463, 1605.0224751081828, 1568.5919996263515, 3466.4940795698276, 2193.7620648697016, 2035.4057238453418, 2308.0292702218253, 2086.087189271138, 2207.5543504586494, 1437.9617784139782, 5989.308935780895, 1300.1156554262298, 1213.1570799749354, 1188.6657940852558, 1149.537240852498, 951.7264860010414, 899.2793166180358, 867.5601066300319, 829.4798691404409, 818.9627142987139, 743.9458972500315, 733.1745463884719, 704.943620111782, 1691.9923690909372, 666.9909289496027, 649.774491056088, 643.909975180541, 601.3855290002913, 597.3980063981741, 590.2796959274498, 586.6125335355126, 549.393812832715, 452.842550574785, 438.66671401374026, 435.73796789634656, 419.53457810303524, 416.06766419233026, 391.3495296500308, 1164.555129749082, 1345.733006646734, 573.8512507515, 498.5208356148581, 5846.789837541826, 1274.3805457307676, 1058.1994053993308, 776.9673540603062, 763.3351266071265, 619.5774718569763, 596.9909741763994, 586.9371798471548, 579.9934700027566, 567.2412304420618, 549.458655710237, 549.0866066967276, 540.3445359019188, 526.497911527455, 508.05130533253606, 505.60220418130297, 486.53066055605154, 487.37655193038876, 467.32312073523605, 436.7974862745255, 421.6052545076745, 403.5045046787482, 385.75893282108797, 389.51844610221275, 384.84424587323235, 383.1112070464665, 381.0521955820664, 374.4986108678672, 370.02264538524855, 369.23144312473863, 1423.571739384322, 2670.2306107865834, 671.26772248212, 888.1952494057872, 871.5128493569205, 763.380895629616, 677.0080432658908, 589.2002726001939, 546.8269125443564, 530.2170459330878, 520.7357981160209, 524.3089417138549, 474.1730799013443, 450.044175131238, 425.2143753365204, 393.55094349642263, 387.55894343009606, 339.8546372496319, 341.591197010846, 338.80981865371683, 334.89373952018735, 329.4195863520976, 320.4742025531838, 309.41779349750703, 297.50577466490626, 294.5678507836019, 291.02048329119646, 283.5391939045703, 270.99303057066066, 264.56149995799115, 253.5024173941978, 249.67200675988286, 243.6730323245565, 473.58432691827596, 1123.394859293622, 388.7298528055538, 461.4312564571188, 1026.0039949283764, 917.6370014205122, 477.52055845040616, 451.5249530778942, 386.2263293148073, 328.5288054277795, 322.5963400653972, 310.36090070937, 261.7753508427349, 251.8507750336372, 244.65097595325344, 237.37302229618544, 226.5963980096106, 229.17320348037546, 224.5888913729237, 207.82763710610544, 207.71506232507124, 206.13297305498799, 202.96992910185637, 185.93244247065348, 179.04287378708432, 175.44211671018002, 168.8880295813886, 170.78513826100362, 164.99272843307102, 163.89419751869457, 160.85760724846614, 154.73863424756513, 153.46980973497125, 152.8740328057877], \"Total\": [5847.0, 5992.0, 12335.0, 8213.0, 3028.0, 6026.0, 2208.0, 3210.0, 1693.0, 1026.0, 4042.0, 4003.0, 1429.0, 918.0, 1438.0, 1505.0, 3582.0, 3537.0, 1275.0, 3525.0, 1300.0, 3470.0, 3469.0, 1213.0, 1189.0, 1191.0, 1150.0, 3060.0, 1059.0, 2847.0, 12335.247413156778, 8213.828443759545, 6026.868137410548, 4042.3534129240534, 4003.1060024860094, 3582.6457350788387, 3537.6821624158783, 3525.3453148217577, 3470.9498579307606, 3060.1679287293236, 2847.5341196197523, 2781.861798694225, 2761.4276795771975, 2761.485873048274, 2584.488792706237, 2468.68403575931, 2463.4834111417426, 2457.261482501666, 2438.725747136727, 2350.6628802275873, 2188.8923325837272, 2031.19365889808, 2019.2408771840142, 1981.9476509299934, 1874.6478591851826, 1865.6730495197787, 1814.3724832585021, 1641.879306061796, 1605.8274567504575, 1569.3964355411083, 3469.180835171188, 2197.106584116726, 2038.4050324823938, 2326.4557356759924, 3210.082507409606, 2208.368230905607, 1438.7707560165677, 5992.955585821835, 1300.927644136767, 1213.967838741879, 1189.47890407367, 1150.346724312797, 952.5375107747967, 900.0938781039036, 868.3740187259864, 830.2938997273525, 819.7759167929757, 744.7602529379639, 733.9911507388853, 705.7537923681598, 1693.9889680192234, 667.8016219301423, 650.5857590200028, 644.7213745309639, 602.1976949383859, 598.2108652636456, 591.0935412907962, 587.4301315458173, 550.2084324549421, 453.6557105669592, 439.4853644813175, 436.55253393469155, 420.3475071140659, 416.8834169732106, 392.1604372785468, 1191.4835422451572, 1505.58353413079, 911.0780100903394, 983.2726464895352, 5847.599537752168, 1275.189717086921, 1059.0107903227151, 777.7782829354684, 764.1460602540218, 620.3829485033264, 597.8040784551816, 587.7461651851487, 580.8029372703829, 568.0500772101885, 550.269244626646, 549.8981509439307, 541.15724383549, 527.3095619927011, 508.8658594911554, 506.41845773783155, 487.3368472677628, 488.1858657762173, 468.13017188798597, 437.6090856869103, 422.4154065081482, 404.3165056168382, 386.5646638840979, 390.33489123784585, 385.65728251864897, 383.9227167364654, 381.86567118546924, 375.311904339113, 370.83538731063067, 370.0509091488088, 1429.1151227932953, 3028.1556969099247, 746.678197280614, 889.0077127064557, 872.3358121645363, 764.1898904622498, 677.8169501861918, 590.0141029429227, 547.6349873071232, 531.0275687511362, 521.5434264030715, 525.1233871141399, 474.98180185826203, 450.85812377272435, 426.0212607767146, 394.36540511558763, 388.3644977803624, 340.6618731974786, 342.4042644848855, 339.62401042303253, 335.70210355948353, 330.22598443371214, 321.2846651338822, 310.226979940132, 298.31993373760673, 295.3775952515548, 291.8357488787917, 284.34786043422577, 271.80571442326743, 265.37662892359515, 254.32051480423624, 250.48504101934586, 244.48158379483468, 545.2997763618656, 3210.082507409606, 598.3881098549973, 983.2726464895352, 1026.826995025791, 918.4603280975388, 478.3487743506749, 452.35083221334463, 387.0446571249287, 329.3545775665597, 323.42758502337585, 311.18751929881813, 262.5993113196327, 252.67923261161383, 245.47618054439903, 238.19880380050895, 227.42817822531214, 230.0164104599248, 225.42244171961016, 208.65591942683284, 208.5441310208067, 206.9582731521538, 203.8014778495268, 186.76462557026952, 179.87933987355143, 176.27687455522553, 169.71535827545713, 171.622489243789, 165.82192921095773, 164.73201787515237, 161.6803704689267, 155.56403218565228, 154.29835504551474, 153.70435531267498], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.0159, -3.4226, -3.7322, -4.1317, -4.1415, -4.2525, -4.2651, -4.2686, -4.2841, -4.4101, -4.4822, -4.5055, -4.5129, -4.5129, -4.5791, -4.625, -4.6271, -4.6296, -4.6372, -4.674, -4.7453, -4.8201, -4.826, -4.8447, -4.9003, -4.9051, -4.933, -5.033, -5.0552, -5.0782, -4.2852, -4.7427, -4.8176, -4.6919, -4.793, -3.593, -4.0217, -2.5949, -4.1224, -4.1917, -4.2121, -4.2455, -4.4344, -4.4911, -4.527, -4.5718, -4.5846, -4.6807, -4.6953, -4.7345, -3.859, -4.7899, -4.816, -4.8251, -4.8934, -4.9001, -4.9121, -4.9183, -4.9838, -5.1771, -5.2089, -5.2156, -5.2535, -5.2618, -5.323, -4.2326, -4.088, -4.9403, -5.081, -2.5663, -4.0898, -4.2757, -4.5846, -4.6023, -4.811, -4.8481, -4.8651, -4.877, -4.8992, -4.9311, -4.9317, -4.9478, -4.9737, -5.0094, -5.0142, -5.0527, -5.051, -5.093, -5.1605, -5.1959, -5.2398, -5.2848, -5.2751, -5.2871, -5.2917, -5.2971, -5.3144, -5.3264, -5.3286, -3.9791, -3.3501, -4.7308, -4.2522, -4.2712, -4.4037, -4.5237, -4.6626, -4.7373, -4.7681, -4.7862, -4.7793, -4.8798, -4.9321, -4.9888, -5.0662, -5.0815, -5.2129, -5.2078, -5.216, -5.2276, -5.2441, -5.2716, -5.3067, -5.346, -5.3559, -5.368, -5.3941, -5.4393, -5.4633, -5.506, -5.5213, -5.5456, -4.8811, -4.0173, -5.0785, -4.9071, -3.3183, -3.4299, -4.0831, -4.1391, -4.2953, -4.4571, -4.4753, -4.514, -4.6842, -4.7229, -4.7519, -4.7821, -4.8286, -4.8173, -4.8375, -4.915, -4.9156, -4.9232, -4.9387, -5.0263, -5.0641, -5.0844, -5.1225, -5.1113, -5.1458, -5.1525, -5.1712, -5.21, -5.2182, -5.2221], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6838, 0.6838, 0.6837, 0.6837, 0.6837, 0.6837, 0.6837, 0.6837, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6836, 0.6835, 0.6835, 0.6835, 0.6835, 0.6835, 0.6835, 0.6835, 0.6834, 0.6834, 0.6834, 0.6834, 0.6831, 0.6824, 0.6824, 0.6759, 0.2529, 1.827, 1.8268, 1.8267, 1.8267, 1.8267, 1.8266, 1.8266, 1.8265, 1.8264, 1.8264, 1.8263, 1.8263, 1.8262, 1.8262, 1.8262, 1.8261, 1.8261, 1.8261, 1.8261, 1.826, 1.826, 1.8259, 1.8259, 1.8258, 1.8255, 1.8255, 1.8255, 1.8254, 1.8254, 1.8253, 1.8045, 1.7151, 1.3651, 1.1481, 1.8798, 1.8793, 1.8792, 1.8789, 1.8789, 1.8787, 1.8786, 1.8786, 1.8786, 1.8786, 1.8785, 1.8785, 1.8785, 1.8784, 1.8784, 1.8784, 1.8783, 1.8783, 1.8783, 1.8781, 1.8781, 1.878, 1.8779, 1.8779, 1.8779, 1.8779, 1.8778, 1.8778, 1.8778, 1.8778, 1.8761, 1.7542, 1.7735, 2.0776, 2.0776, 2.0775, 2.0774, 2.0772, 2.0771, 2.077, 2.077, 2.077, 2.0769, 2.0768, 2.0767, 2.0765, 2.0765, 2.0762, 2.0762, 2.0762, 2.0761, 2.0761, 2.076, 2.0759, 2.0758, 2.0758, 2.0758, 2.0757, 2.0756, 2.0755, 2.0753, 2.0753, 2.0752, 1.9376, 1.0286, 1.6472, 1.322, 2.8674, 2.8673, 2.8665, 2.8664, 2.8661, 2.8657, 2.8657, 2.8656, 2.8651, 2.865, 2.8649, 2.8648, 2.8646, 2.8646, 2.8645, 2.8643, 2.8643, 2.8642, 2.8642, 2.8638, 2.8636, 2.8635, 2.8634, 2.8633, 2.8632, 2.8631, 2.8631, 2.8629, 2.8629, 2.8628]}, \"token.table\": {\"Topic\": [3, 3, 4, 2, 5, 1, 4, 4, 5, 1, 2, 1, 2, 1, 3, 3, 4, 2, 4, 5, 2, 2, 4, 3, 4, 5, 1, 2, 5, 3, 2, 4, 3, 2, 2, 5, 2, 3, 2, 4, 1, 2, 5, 1, 2, 1, 3, 1, 2, 4, 3, 3, 1, 1, 1, 2, 5, 5, 5, 4, 1, 1, 1, 2, 1, 1, 4, 2, 1, 1, 4, 5, 4, 5, 2, 3, 1, 3, 3, 4, 2, 2, 3, 3, 3, 5, 1, 3, 2, 3, 4, 2, 2, 5, 4, 5, 1, 2, 3, 4, 1, 1, 5, 2, 5, 3, 2, 3, 4, 4, 2, 5, 1, 4, 1, 1, 3, 3, 3, 4, 5, 3, 1, 4, 3, 1, 3, 2, 4, 5, 4, 2, 1, 2, 4, 5, 4, 3, 1, 3, 3, 1, 2, 5, 3, 3, 4, 1, 1, 5, 4, 1, 2, 1, 5, 4, 1, 1, 1, 5, 5, 5, 2, 5, 1, 4, 2, 2, 1, 4, 3, 1, 3, 1, 1, 5, 4, 3, 4, 2, 5], \"Freq\": [0.9971600957521599, 0.9982956823365129, 0.9979085518022108, 0.9996985914720589, 0.9954174667904359, 0.9994644514620841, 0.9962874380227391, 0.9989580418895904, 0.9992708785526871, 0.021821535151889067, 0.9777726327673371, 0.999639245729603, 0.9987343242983576, 0.10044487742262784, 0.8986468366744438, 0.9978615386772096, 0.9987947333185347, 0.9990996436490016, 0.9976027938726517, 0.9981259997168533, 0.9989791977552981, 0.998881106537706, 0.9970356972627413, 0.9991420412436515, 0.9990614544263299, 0.997717772690945, 0.105606893536993, 0.8940055264200791, 0.9981173035432401, 0.9982984523818886, 0.9980111266641291, 0.9960448960939219, 0.9977472826509652, 0.9984416364762196, 0.9981499691429411, 0.9927564261707765, 0.9988956071793418, 0.9991736917732011, 0.997803682416225, 0.9980966877882921, 0.3698914870819725, 0.6300228889764161, 0.9961839109052513, 0.0005005877245440322, 0.9993399607647364, 0.9985860567078612, 0.00136543216505177, 0.023391274111116835, 0.5074889470194478, 0.46884249414021134, 0.9965044957968409, 0.99865494652151, 0.9995923360092025, 0.9997947040853302, 0.0005903226165453116, 0.998825867194667, 0.9963742763817078, 0.9968564542590759, 0.9963729156561483, 0.9982812225371148, 0.9998559554662961, 0.9995218587486159, 0.9990831163544603, 0.0005765049719298675, 0.9999020479439827, 0.9997024072355906, 0.9990734351673658, 0.9998332565645286, 0.9994123362423613, 0.9998240537628615, 0.9980649427419507, 0.9915854252293762, 0.9960014738538895, 0.9960673599721462, 0.9987996106870399, 0.9977330478993258, 0.1178935417238618, 0.881724807850731, 0.9986175392394596, 0.9971362354269393, 0.9987847066505907, 0.9992027476256027, 0.9990455334997983, 0.9989993511614506, 0.9981514354943042, 0.9989234169168696, 0.9997229148204462, 0.9986081511859969, 0.9995692884426285, 0.9985392770295548, 0.9988404917110106, 0.9992677741186251, 0.9989319329540824, 0.9953697277351687, 0.9988664747312621, 0.9957918795772586, 0.9998991403624732, 0.9994357064486001, 0.34927164587318643, 0.6500797619362179, 0.9996902079410884, 0.9997237139148145, 0.9994988045934523, 0.9986496421136856, 0.9973118779703678, 0.9992171835370527, 0.9994642954665678, 0.9987304635413254, 0.9980570963481583, 0.9985807758387661, 0.997040911911972, 0.9973009390371419, 0.9998124273152437, 0.9988193357185732, 0.999654410196556, 0.003498668455923401, 0.9964207762469846, 0.9985002078612552, 0.997516521438086, 0.9987397209993737, 0.9950433020839355, 0.9975966081290814, 0.6498275340851938, 0.3498352448598622, 0.9983666958283294, 0.9998988740869966, 0.9975857743083981, 0.9979758554483762, 0.9984429387550128, 0.9986779574681456, 0.9987216523608258, 0.9985546074882652, 0.9998071724975394, 0.9978809016208304, 0.9989275482412512, 0.995905940067961, 0.9996150425560278, 0.9990165924307021, 0.9997263406359529, 0.9993827223906617, 0.9990670273834713, 0.9920670161942153, 0.007737091114166325, 0.9973908111528086, 0.999897472843635, 0.9993087999201142, 0.9981626433824414, 0.9997473961759245, 0.9996183448893903, 0.9955563108823984, 0.9979329695276304, 0.9983295604023077, 0.000981159273122661, 0.9998197602759, 0.995111501553377, 0.998776637764411, 0.9993854734231883, 0.9998451237450973, 0.9999125724824248, 0.9955811393722194, 0.9957849526246406, 0.994967213179152, 0.9992869364096091, 0.9992244245210559, 0.9994866307429433, 0.9980635928701691, 0.9990535013567962, 0.9991732861306786, 0.9994847162769704, 0.9980301837571585, 0.9976934116543126, 0.9998037692725852, 0.9975708723677778, 0.9997180028522324, 0.999810874511193, 0.9991946111372246, 0.9978607178013656, 0.13020361107370745, 0.8692466429427793, 0.9995973832978207, 0.9980601761712969], \"Term\": [\"able\", \"absolutely\", \"act\", \"ad\", \"agenda\", \"also\", \"answer\", \"ask\", \"audio\", \"back\", \"back\", \"bad\", \"base\", \"become\", \"become\", \"begin\", \"believe\", \"bit\", \"book\", \"buy\", \"call\", \"case\", \"character\", \"check\", \"child\", \"claim\", \"come\", \"come\", \"community\", \"completely\", \"conversation\", \"country\", \"cover\", \"day\", \"different\", \"disagree\", \"disappoint\", \"discuss\", \"discussion\", \"else\", \"end\", \"end\", \"entire\", \"episode\", \"episode\", \"even\", \"even\", \"fact\", \"fact\", \"fact\", \"family\", \"far\", \"feel\", \"find\", \"first\", \"first\", \"form\", \"free\", \"frustrating\", \"fun\", \"get\", \"give\", \"go\", \"go\", \"good\", \"great\", \"guess\", \"guest\", \"guy\", \"hear\", \"help\", \"helpful\", \"history\", \"honest\", \"hope\", \"horrible\", \"host\", \"host\", \"hour\", \"important\", \"information\", \"interesting\", \"interview\", \"issue\", \"joke\", \"kid\", \"know\", \"lack\", \"last\", \"laugh\", \"learn\", \"least\", \"less\", \"lie\", \"life\", \"line\", \"listen\", \"little\", \"live\", \"live\", \"love\", \"make\", \"man\", \"mean\", \"medium\", \"mention\", \"minute\", \"miss\", \"money\", \"mostly\", \"move\", \"movie\", \"much\", \"narrator\", \"need\", \"new\", \"new\", \"old\", \"other\", \"otherwise\", \"parent\", \"pay\", \"people\", \"people\", \"pod\", \"podcast\", \"politic\", \"quality\", \"question\", \"quite\", \"racist\", \"rather\", \"really\", \"recent\", \"recommend\", \"relationship\", \"right\", \"sad\", \"say\", \"season\", \"see\", \"seem\", \"seem\", \"sentence\", \"show\", \"side\", \"sorry\", \"sound\", \"story\", \"suffer\", \"support\", \"take\", \"take\", \"talk\", \"talking\", \"thank\", \"thing\", \"think\", \"time\", \"tired\", \"title\", \"today\", \"topic\", \"trump\", \"try\", \"type\", \"understand\", \"unfortunately\", \"use\", \"victim\", \"view\", \"want\", \"watch\", \"way\", \"well\", \"woman\", \"world\", \"wrong\", \"wrong\", \"year\", \"yet\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 1, 3, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el20551404057676337125852239420\", ldavis_el20551404057676337125852239420_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el20551404057676337125852239420\", ldavis_el20551404057676337125852239420_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el20551404057676337125852239420\", ldavis_el20551404057676337125852239420_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.414969  0.014703       1        1  50.465380\n",
       "4     -0.082522 -0.352705       2        1  16.084382\n",
       "0     -0.102546  0.248776       3        1  15.259310\n",
       "2     -0.100107  0.063493       4        1  12.511046\n",
       "3     -0.129794  0.025733       5        1   5.679882, topic_info=         Term          Freq         Total Category  logprob  loglift\n",
       "128      show   5847.000000   5847.000000  Default  30.0000  30.0000\n",
       "28    episode   5992.000000   5992.000000  Default  29.0000  29.0000\n",
       "5     podcast  12335.000000  12335.000000  Default  28.0000  28.0000\n",
       "65     listen   8213.000000   8213.000000  Default  27.0000  27.0000\n",
       "164      host   3028.000000   3028.000000  Default  26.0000  26.0000\n",
       "...       ...           ...           ...      ...      ...      ...\n",
       "1341   suffer    163.894198    164.732018   Topic5  -5.1525   2.8631\n",
       "1324     line    160.857607    161.680370   Topic5  -5.1712   2.8631\n",
       "795      form    154.738634    155.564032   Topic5  -5.2100   2.8629\n",
       "1248  helpful    153.469810    154.298355   Topic5  -5.2182   2.8629\n",
       "193    agenda    152.874033    153.704355   Topic5  -5.2221   2.8628\n",
       "\n",
       "[196 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "832       3  0.997160        able\n",
       "151       3  0.998296  absolutely\n",
       "1401      4  0.997909         act\n",
       "45        2  0.999699          ad\n",
       "193       5  0.995417      agenda\n",
       "...     ...       ...         ...\n",
       "230       4  0.997861       world\n",
       "177       3  0.130204       wrong\n",
       "177       4  0.869247       wrong\n",
       "668       2  0.999597        year\n",
       "1309      5  0.998060         yet\n",
       "\n",
       "[181 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 5, 1, 3, 4])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51315ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
